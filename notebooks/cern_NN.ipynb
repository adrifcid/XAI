{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T11:10:13.201768Z",
     "start_time": "2020-12-23T11:10:13.144042Z"
    },
    "executionInfo": {
     "elapsed": 2663,
     "status": "ok",
     "timestamp": 1605724241303,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "4245f72gXPti"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-59d36ec978f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 561518,
     "status": "ok",
     "timestamp": 1605724804114,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "9r1fzh7JYSax",
    "outputId": "9c7b0775-b2e8-4363-cce7-f082e101b5ad"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-959701a5-1cfc-4ade-ac18-5b75abccfd1e\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-959701a5-1cfc-4ade-ac18-5b75abccfd1e\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train.csv to train.csv\n"
     ]
    }
   ],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T11:12:17.984284Z",
     "start_time": "2020-12-23T11:12:16.430000Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1605727216334,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "9Bmgp038dXjn",
    "outputId": "2bf96884-02a0-4584-c182-f80d3accb3f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_OWNPV_CHI2</th>\n",
       "      <th>B_IPCHI2_OWNPV</th>\n",
       "      <th>B_FDCHI2_OWNPV</th>\n",
       "      <th>B_DIRA_OWNPV</th>\n",
       "      <th>B_PT</th>\n",
       "      <th>Kst_892_0_IP_OWNPV</th>\n",
       "      <th>Kst_892_0_cosThetaH</th>\n",
       "      <th>Kplus_IP_OWNPV</th>\n",
       "      <th>Kplus_P</th>\n",
       "      <th>piminus_IP_OWNPV</th>\n",
       "      <th>piminus_P</th>\n",
       "      <th>gamma_PT</th>\n",
       "      <th>piminus_ETA</th>\n",
       "      <th>Kplus_ETA</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.878847</td>\n",
       "      <td>2.662533</td>\n",
       "      <td>2924.690991</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>19085.568945</td>\n",
       "      <td>0.569198</td>\n",
       "      <td>-0.575502</td>\n",
       "      <td>0.581565</td>\n",
       "      <td>66850.893711</td>\n",
       "      <td>0.637969</td>\n",
       "      <td>14298.486178</td>\n",
       "      <td>7940.694301</td>\n",
       "      <td>2.628526</td>\n",
       "      <td>2.680116</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.233566</td>\n",
       "      <td>0.092746</td>\n",
       "      <td>346.948714</td>\n",
       "      <td>0.999997</td>\n",
       "      <td>6631.244546</td>\n",
       "      <td>0.248707</td>\n",
       "      <td>-0.615941</td>\n",
       "      <td>0.277898</td>\n",
       "      <td>39274.475071</td>\n",
       "      <td>0.148815</td>\n",
       "      <td>11553.163934</td>\n",
       "      <td>3904.681337</td>\n",
       "      <td>3.292504</td>\n",
       "      <td>3.085754</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.113632</td>\n",
       "      <td>2.442423</td>\n",
       "      <td>238.553023</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>7740.918989</td>\n",
       "      <td>0.222347</td>\n",
       "      <td>0.249383</td>\n",
       "      <td>0.216576</td>\n",
       "      <td>27757.153899</td>\n",
       "      <td>0.249840</td>\n",
       "      <td>24081.196003</td>\n",
       "      <td>4738.891687</td>\n",
       "      <td>3.433676</td>\n",
       "      <td>3.121906</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.286133</td>\n",
       "      <td>6.337556</td>\n",
       "      <td>227.375132</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>6740.281614</td>\n",
       "      <td>0.347316</td>\n",
       "      <td>0.591884</td>\n",
       "      <td>0.306927</td>\n",
       "      <td>10593.207077</td>\n",
       "      <td>0.400748</td>\n",
       "      <td>11343.521945</td>\n",
       "      <td>3308.943750</td>\n",
       "      <td>2.291867</td>\n",
       "      <td>2.200712</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.474274</td>\n",
       "      <td>7.632751</td>\n",
       "      <td>106.730650</td>\n",
       "      <td>0.999905</td>\n",
       "      <td>5556.388794</td>\n",
       "      <td>0.204273</td>\n",
       "      <td>0.655850</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>11801.249543</td>\n",
       "      <td>0.223101</td>\n",
       "      <td>25940.693317</td>\n",
       "      <td>4026.326871</td>\n",
       "      <td>3.290073</td>\n",
       "      <td>3.281829</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      B_OWNPV_CHI2                    B_IPCHI2_OWNPV   \\\n",
       "0                         28.878847                          2.662533   \n",
       "1                         34.233566                          0.092746   \n",
       "2                         36.113632                          2.442423   \n",
       "3                         14.286133                          6.337556   \n",
       "4                         60.474274                          7.632751   \n",
       "\n",
       "                    B_FDCHI2_OWNPV                      B_DIRA_OWNPV   \\\n",
       "0                       2924.690991                          0.999997   \n",
       "1                        346.948714                          0.999997   \n",
       "2                        238.553023                          0.999986   \n",
       "3                        227.375132                          0.999806   \n",
       "4                        106.730650                          0.999905   \n",
       "\n",
       "                              B_PT                Kst_892_0_IP_OWNPV   \\\n",
       "0                      19085.568945                          0.569198   \n",
       "1                       6631.244546                          0.248707   \n",
       "2                       7740.918989                          0.222347   \n",
       "3                       6740.281614                          0.347316   \n",
       "4                       5556.388794                          0.204273   \n",
       "\n",
       "               Kst_892_0_cosThetaH                    Kplus_IP_OWNPV   \\\n",
       "0                         -0.575502                          0.581565   \n",
       "1                         -0.615941                          0.277898   \n",
       "2                          0.249383                          0.216576   \n",
       "3                          0.591884                          0.306927   \n",
       "4                          0.655850                          0.196600   \n",
       "\n",
       "                           Kplus_P                  piminus_IP_OWNPV   \\\n",
       "0                      66850.893711                          0.637969   \n",
       "1                      39274.475071                          0.148815   \n",
       "2                      27757.153899                          0.249840   \n",
       "3                      10593.207077                          0.400748   \n",
       "4                      11801.249543                          0.223101   \n",
       "\n",
       "                         piminus_P                          gamma_PT   \\\n",
       "0                      14298.486178                       7940.694301   \n",
       "1                      11553.163934                       3904.681337   \n",
       "2                      24081.196003                       4738.891687   \n",
       "3                      11343.521945                       3308.943750   \n",
       "4                      25940.693317                       4026.326871   \n",
       "\n",
       "                       piminus_ETA                         Kplus_ETA   signal  \n",
       "0                          2.628526                          2.680116     1.0  \n",
       "1                          3.292504                          3.085754     1.0  \n",
       "2                          3.433676                          3.121906     1.0  \n",
       "3                          2.291867                          2.200712     0.0  \n",
       "4                          3.290073                          3.281829     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "sc = StandardScaler()\n",
    "data.drop([\"Id\", \"BUTTER\"], axis=1, inplace=True)\n",
    "\n",
    "# X = sc.fit_transform(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T11:12:20.671851Z",
     "start_time": "2020-12-23T11:12:20.583710Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1605727218048,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "BBhQUBkGkZ5X",
    "outputId": "a81a9ec2-99f3-4d18-f69a-8a9695702fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(212662, 14)\n",
      "(212662,)\n"
     ]
    }
   ],
   "source": [
    "X = sc.fit_transform(data.iloc[:, :-1].values)\n",
    "y = data.iloc[:, -1]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T11:12:23.017043Z",
     "start_time": "2020-12-23T11:12:22.950021Z"
    },
    "executionInfo": {
     "elapsed": 568,
     "status": "ok",
     "timestamp": 1605727221600,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "z2K2-z8KmXul"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4db0c6b6b7e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# y = ohe.fit_transform(y.to_numpy().reshape(-1, 1)).toarray()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import numpy as np\n",
    "\n",
    "# ohe = OneHotEncoder()\n",
    "# y = ohe.fit_transform(y.to_numpy().reshape(-1, 1)).toarray()\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "executionInfo": {
     "elapsed": 706,
     "status": "error",
     "timestamp": 1605724861255,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "_DF_cp6inAhL",
    "outputId": "ea3019d9-ab39-40a9-80a6-6376753b6a54"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-55361649dcd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2122\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2124\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         raise ValueError('test_size={0} should be either positive and smaller'\n\u001b[1;32m   1756\u001b[0m                          \u001b[0;34m' than the number of samples {1} or a float in the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m                          '(0, 1) range'.format(test_size, n_samples))\n\u001b[0m\u001b[1;32m   1758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m     if (train_size_type == 'i' and (train_size >= n_samples or train_size <= 0)\n",
      "\u001b[0;31mValueError\u001b[0m: test_size=0.0 should be either positive and smaller than the number of samples 212662 or a float in the (0, 1) range"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 930,
     "status": "ok",
     "timestamp": 1605204874562,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "b8KmuaoFpm9f",
    "outputId": "4f5ea6a7-851b-4927-821c-e1a68d483a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170129, 14)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1402910,
     "status": "ok",
     "timestamp": 1605735100280,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "-1xC_pFenOas",
    "outputId": "6fcc23ec-5c6c-4b67-e2e8-ae6dc67d2e87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.4711 - accuracy: 0.7664\n",
      "Epoch 2/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.4429 - accuracy: 0.7851\n",
      "Epoch 3/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.4358 - accuracy: 0.7902\n",
      "Epoch 4/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.4305 - accuracy: 0.7943\n",
      "Epoch 5/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.4259 - accuracy: 0.7964\n",
      "Epoch 6/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.4196 - accuracy: 0.8000\n",
      "Epoch 7/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.4138 - accuracy: 0.8029\n",
      "Epoch 8/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.4088 - accuracy: 0.8060\n",
      "Epoch 9/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.4052 - accuracy: 0.8080\n",
      "Epoch 10/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.4027 - accuracy: 0.8099\n",
      "Epoch 11/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.4004 - accuracy: 0.8112\n",
      "Epoch 12/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3991 - accuracy: 0.8112\n",
      "Epoch 13/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3974 - accuracy: 0.8120\n",
      "Epoch 14/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3962 - accuracy: 0.8129\n",
      "Epoch 15/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3953 - accuracy: 0.8138\n",
      "Epoch 16/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3941 - accuracy: 0.8143\n",
      "Epoch 17/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3938 - accuracy: 0.8147\n",
      "Epoch 18/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3926 - accuracy: 0.8151\n",
      "Epoch 19/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3918 - accuracy: 0.8158\n",
      "Epoch 20/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3912 - accuracy: 0.8169\n",
      "Epoch 21/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3904 - accuracy: 0.8162\n",
      "Epoch 22/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3900 - accuracy: 0.8165\n",
      "Epoch 23/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3893 - accuracy: 0.8168\n",
      "Epoch 24/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3890 - accuracy: 0.8172\n",
      "Epoch 25/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3886 - accuracy: 0.8173\n",
      "Epoch 26/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3881 - accuracy: 0.8178\n",
      "Epoch 27/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3877 - accuracy: 0.8180\n",
      "Epoch 28/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3875 - accuracy: 0.8181\n",
      "Epoch 29/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3869 - accuracy: 0.8182\n",
      "Epoch 30/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3868 - accuracy: 0.8187\n",
      "Epoch 31/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3861 - accuracy: 0.8186\n",
      "Epoch 32/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3858 - accuracy: 0.8192\n",
      "Epoch 33/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3858 - accuracy: 0.8187\n",
      "Epoch 34/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3851 - accuracy: 0.8194\n",
      "Epoch 35/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3850 - accuracy: 0.8190\n",
      "Epoch 36/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3843 - accuracy: 0.8196\n",
      "Epoch 37/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3844 - accuracy: 0.8200\n",
      "Epoch 38/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3839 - accuracy: 0.8196\n",
      "Epoch 39/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3837 - accuracy: 0.8203\n",
      "Epoch 40/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3835 - accuracy: 0.8203\n",
      "Epoch 41/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3831 - accuracy: 0.8202\n",
      "Epoch 42/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3830 - accuracy: 0.8198\n",
      "Epoch 43/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3824 - accuracy: 0.8208\n",
      "Epoch 44/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3824 - accuracy: 0.8211\n",
      "Epoch 45/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3821 - accuracy: 0.8211\n",
      "Epoch 46/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3820 - accuracy: 0.8211\n",
      "Epoch 47/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3814 - accuracy: 0.8210\n",
      "Epoch 48/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3816 - accuracy: 0.8209\n",
      "Epoch 49/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3811 - accuracy: 0.8212\n",
      "Epoch 50/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3809 - accuracy: 0.8214\n",
      "Epoch 51/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3808 - accuracy: 0.8216\n",
      "Epoch 52/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3805 - accuracy: 0.8228\n",
      "Epoch 53/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3801 - accuracy: 0.8218\n",
      "Epoch 54/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3799 - accuracy: 0.8215\n",
      "Epoch 55/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3794 - accuracy: 0.8227\n",
      "Epoch 56/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3793 - accuracy: 0.8223\n",
      "Epoch 57/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3792 - accuracy: 0.8224\n",
      "Epoch 58/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3789 - accuracy: 0.8230\n",
      "Epoch 59/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3792 - accuracy: 0.8232\n",
      "Epoch 60/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3788 - accuracy: 0.8227\n",
      "Epoch 61/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3787 - accuracy: 0.8231\n",
      "Epoch 62/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3786 - accuracy: 0.8231\n",
      "Epoch 63/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3784 - accuracy: 0.8229\n",
      "Epoch 64/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3781 - accuracy: 0.8235\n",
      "Epoch 65/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3778 - accuracy: 0.8233\n",
      "Epoch 66/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3777 - accuracy: 0.8234\n",
      "Epoch 67/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3776 - accuracy: 0.8236\n",
      "Epoch 68/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3775 - accuracy: 0.8238\n",
      "Epoch 69/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3771 - accuracy: 0.8240\n",
      "Epoch 70/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3769 - accuracy: 0.8238\n",
      "Epoch 71/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3768 - accuracy: 0.8241\n",
      "Epoch 72/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3767 - accuracy: 0.8243\n",
      "Epoch 73/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3765 - accuracy: 0.8244\n",
      "Epoch 74/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3763 - accuracy: 0.8249\n",
      "Epoch 75/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3762 - accuracy: 0.8245\n",
      "Epoch 76/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3760 - accuracy: 0.8249\n",
      "Epoch 77/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3760 - accuracy: 0.8242\n",
      "Epoch 78/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3759 - accuracy: 0.8248\n",
      "Epoch 79/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3756 - accuracy: 0.8250\n",
      "Epoch 80/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3755 - accuracy: 0.8254\n",
      "Epoch 81/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3755 - accuracy: 0.8248\n",
      "Epoch 82/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3753 - accuracy: 0.8249\n",
      "Epoch 83/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3751 - accuracy: 0.8252\n",
      "Epoch 84/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3749 - accuracy: 0.8252\n",
      "Epoch 85/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3748 - accuracy: 0.8252\n",
      "Epoch 86/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3751 - accuracy: 0.8253\n",
      "Epoch 87/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3744 - accuracy: 0.8258\n",
      "Epoch 88/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3744 - accuracy: 0.8253\n",
      "Epoch 89/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3741 - accuracy: 0.8257\n",
      "Epoch 90/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3740 - accuracy: 0.8259\n",
      "Epoch 91/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3742 - accuracy: 0.8256\n",
      "Epoch 92/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3739 - accuracy: 0.8264\n",
      "Epoch 93/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3737 - accuracy: 0.8266\n",
      "Epoch 94/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3735 - accuracy: 0.8261\n",
      "Epoch 95/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3734 - accuracy: 0.8268\n",
      "Epoch 96/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3732 - accuracy: 0.8265\n",
      "Epoch 97/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3733 - accuracy: 0.8259\n",
      "Epoch 98/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3732 - accuracy: 0.8262\n",
      "Epoch 99/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3727 - accuracy: 0.8266\n",
      "Epoch 100/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3731 - accuracy: 0.8265\n",
      "Epoch 101/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3728 - accuracy: 0.8266\n",
      "Epoch 102/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3726 - accuracy: 0.8273\n",
      "Epoch 103/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3723 - accuracy: 0.8271\n",
      "Epoch 104/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3721 - accuracy: 0.8270\n",
      "Epoch 105/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3721 - accuracy: 0.8270\n",
      "Epoch 106/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3720 - accuracy: 0.8269\n",
      "Epoch 107/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3720 - accuracy: 0.8270\n",
      "Epoch 108/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3715 - accuracy: 0.8274\n",
      "Epoch 109/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3719 - accuracy: 0.8269\n",
      "Epoch 110/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3715 - accuracy: 0.8276\n",
      "Epoch 111/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3716 - accuracy: 0.8270\n",
      "Epoch 112/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3711 - accuracy: 0.8275\n",
      "Epoch 113/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3711 - accuracy: 0.8273\n",
      "Epoch 114/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3710 - accuracy: 0.8275\n",
      "Epoch 115/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3707 - accuracy: 0.8279\n",
      "Epoch 116/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3708 - accuracy: 0.8280\n",
      "Epoch 117/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3705 - accuracy: 0.8281\n",
      "Epoch 118/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3700 - accuracy: 0.8278\n",
      "Epoch 119/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3702 - accuracy: 0.8276\n",
      "Epoch 120/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3700 - accuracy: 0.8281\n",
      "Epoch 121/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3701 - accuracy: 0.8279\n",
      "Epoch 122/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3697 - accuracy: 0.8279\n",
      "Epoch 123/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3697 - accuracy: 0.8287\n",
      "Epoch 124/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3700 - accuracy: 0.8275\n",
      "Epoch 125/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3697 - accuracy: 0.8282\n",
      "Epoch 126/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3698 - accuracy: 0.8277\n",
      "Epoch 127/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3695 - accuracy: 0.8284\n",
      "Epoch 128/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3695 - accuracy: 0.8284\n",
      "Epoch 129/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3693 - accuracy: 0.8281\n",
      "Epoch 130/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3688 - accuracy: 0.8285\n",
      "Epoch 131/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3692 - accuracy: 0.8281\n",
      "Epoch 132/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3692 - accuracy: 0.8283\n",
      "Epoch 133/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3689 - accuracy: 0.8288\n",
      "Epoch 134/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3687 - accuracy: 0.8285\n",
      "Epoch 135/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3688 - accuracy: 0.8285\n",
      "Epoch 136/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3687 - accuracy: 0.8282\n",
      "Epoch 137/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3686 - accuracy: 0.8289\n",
      "Epoch 138/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3681 - accuracy: 0.8285\n",
      "Epoch 139/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3682 - accuracy: 0.8285\n",
      "Epoch 140/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3680 - accuracy: 0.8287\n",
      "Epoch 141/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3677 - accuracy: 0.8293\n",
      "Epoch 142/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3680 - accuracy: 0.8286\n",
      "Epoch 143/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3679 - accuracy: 0.8288\n",
      "Epoch 144/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3678 - accuracy: 0.8291\n",
      "Epoch 145/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3673 - accuracy: 0.8295\n",
      "Epoch 146/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3673 - accuracy: 0.8295\n",
      "Epoch 147/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3675 - accuracy: 0.8287\n",
      "Epoch 148/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3674 - accuracy: 0.8291\n",
      "Epoch 149/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3671 - accuracy: 0.8294\n",
      "Epoch 150/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3671 - accuracy: 0.8289\n",
      "Epoch 151/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3670 - accuracy: 0.8292\n",
      "Epoch 152/1000\n",
      "6646/6646 [==============================] - 7s 1ms/step - loss: 0.3666 - accuracy: 0.8298\n",
      "Epoch 153/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3667 - accuracy: 0.8295\n",
      "Epoch 154/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3666 - accuracy: 0.8294\n",
      "Epoch 155/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3663 - accuracy: 0.8290\n",
      "Epoch 156/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3661 - accuracy: 0.8297\n",
      "Epoch 157/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3660 - accuracy: 0.8303\n",
      "Epoch 158/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3658 - accuracy: 0.8298\n",
      "Epoch 159/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3659 - accuracy: 0.8302\n",
      "Epoch 160/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3655 - accuracy: 0.8298\n",
      "Epoch 161/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3657 - accuracy: 0.8302\n",
      "Epoch 162/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3654 - accuracy: 0.8302\n",
      "Epoch 163/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3653 - accuracy: 0.8296\n",
      "Epoch 164/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3650 - accuracy: 0.8304\n",
      "Epoch 165/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3653 - accuracy: 0.8301\n",
      "Epoch 166/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3652 - accuracy: 0.8298\n",
      "Epoch 167/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3650 - accuracy: 0.8304\n",
      "Epoch 168/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3650 - accuracy: 0.8304\n",
      "Epoch 169/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3648 - accuracy: 0.8305\n",
      "Epoch 170/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3650 - accuracy: 0.8302\n",
      "Epoch 171/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3652 - accuracy: 0.8308\n",
      "Epoch 172/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3651 - accuracy: 0.8304\n",
      "Epoch 173/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3648 - accuracy: 0.8300\n",
      "Epoch 174/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3650 - accuracy: 0.8310\n",
      "Epoch 175/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3645 - accuracy: 0.8302\n",
      "Epoch 176/1000\n",
      "6646/6646 [==============================] - 10s 1ms/step - loss: 0.3645 - accuracy: 0.8310\n",
      "Epoch 177/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3646 - accuracy: 0.8305\n",
      "Epoch 178/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3646 - accuracy: 0.8309\n",
      "Epoch 179/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3646 - accuracy: 0.8309\n",
      "Epoch 180/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3643 - accuracy: 0.8305\n",
      "Epoch 181/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3644 - accuracy: 0.8307\n",
      "Epoch 182/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3642 - accuracy: 0.8308\n",
      "Epoch 183/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3643 - accuracy: 0.8305\n",
      "Epoch 184/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3643 - accuracy: 0.8304\n",
      "Epoch 185/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3640 - accuracy: 0.8303\n",
      "Epoch 186/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3641 - accuracy: 0.8307\n",
      "Epoch 187/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3640 - accuracy: 0.8309\n",
      "Epoch 188/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3641 - accuracy: 0.8310\n",
      "Epoch 189/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3640 - accuracy: 0.8310\n",
      "Epoch 190/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3639 - accuracy: 0.8303\n",
      "Epoch 191/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3637 - accuracy: 0.8313\n",
      "Epoch 192/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3637 - accuracy: 0.8306\n",
      "Epoch 193/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3639 - accuracy: 0.8309\n",
      "Epoch 194/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3638 - accuracy: 0.8309\n",
      "Epoch 195/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3636 - accuracy: 0.8309\n",
      "Epoch 196/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3637 - accuracy: 0.8305\n",
      "Epoch 197/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3635 - accuracy: 0.8307\n",
      "Epoch 198/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3633 - accuracy: 0.8313\n",
      "Epoch 199/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3633 - accuracy: 0.8312\n",
      "Epoch 200/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3633 - accuracy: 0.8310\n",
      "Epoch 201/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3632 - accuracy: 0.8313\n",
      "Epoch 202/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3633 - accuracy: 0.8314\n",
      "Epoch 203/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3630 - accuracy: 0.8308\n",
      "Epoch 204/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3631 - accuracy: 0.8310\n",
      "Epoch 205/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3630 - accuracy: 0.8314\n",
      "Epoch 206/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3631 - accuracy: 0.8314\n",
      "Epoch 207/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3631 - accuracy: 0.8313\n",
      "Epoch 208/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3629 - accuracy: 0.8314\n",
      "Epoch 209/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3627 - accuracy: 0.8312\n",
      "Epoch 210/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3630 - accuracy: 0.8316\n",
      "Epoch 211/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3627 - accuracy: 0.8315\n",
      "Epoch 212/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3628 - accuracy: 0.8314\n",
      "Epoch 213/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3628 - accuracy: 0.8315\n",
      "Epoch 214/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3624 - accuracy: 0.8312\n",
      "Epoch 215/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3626 - accuracy: 0.8317\n",
      "Epoch 216/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3624 - accuracy: 0.8314\n",
      "Epoch 217/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3623 - accuracy: 0.8317\n",
      "Epoch 218/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3627 - accuracy: 0.8317\n",
      "Epoch 219/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3623 - accuracy: 0.8317\n",
      "Epoch 220/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3624 - accuracy: 0.8320\n",
      "Epoch 221/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3622 - accuracy: 0.8319\n",
      "Epoch 222/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3622 - accuracy: 0.8314\n",
      "Epoch 223/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3622 - accuracy: 0.8320\n",
      "Epoch 224/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3621 - accuracy: 0.8319\n",
      "Epoch 225/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3622 - accuracy: 0.8317\n",
      "Epoch 226/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3621 - accuracy: 0.8317\n",
      "Epoch 227/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3620 - accuracy: 0.8323\n",
      "Epoch 228/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3622 - accuracy: 0.8319\n",
      "Epoch 229/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3618 - accuracy: 0.8320\n",
      "Epoch 230/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3619 - accuracy: 0.8321\n",
      "Epoch 231/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3619 - accuracy: 0.8323\n",
      "Epoch 232/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3618 - accuracy: 0.8319\n",
      "Epoch 233/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3617 - accuracy: 0.8319\n",
      "Epoch 234/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3615 - accuracy: 0.8326\n",
      "Epoch 235/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3618 - accuracy: 0.8320\n",
      "Epoch 236/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3615 - accuracy: 0.8319\n",
      "Epoch 237/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3616 - accuracy: 0.8319\n",
      "Epoch 238/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3615 - accuracy: 0.8316\n",
      "Epoch 239/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3615 - accuracy: 0.8322\n",
      "Epoch 240/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3615 - accuracy: 0.8322\n",
      "Epoch 241/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3614 - accuracy: 0.8323\n",
      "Epoch 242/1000\n",
      "6646/6646 [==============================] - 10s 2ms/step - loss: 0.3615 - accuracy: 0.8317\n",
      "Epoch 243/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3613 - accuracy: 0.8323\n",
      "Epoch 244/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3612 - accuracy: 0.8322\n",
      "Epoch 245/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3614 - accuracy: 0.8320\n",
      "Epoch 246/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3617 - accuracy: 0.8317\n",
      "Epoch 247/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3611 - accuracy: 0.8322\n",
      "Epoch 248/1000\n",
      "6646/6646 [==============================] - 11s 2ms/step - loss: 0.3613 - accuracy: 0.8327\n",
      "Epoch 249/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3610 - accuracy: 0.8320\n",
      "Epoch 250/1000\n",
      "6646/6646 [==============================] - 10s 2ms/step - loss: 0.3611 - accuracy: 0.8323\n",
      "Epoch 251/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3616 - accuracy: 0.8322\n",
      "Epoch 252/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3609 - accuracy: 0.8320\n",
      "Epoch 253/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3609 - accuracy: 0.8326\n",
      "Epoch 254/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3611 - accuracy: 0.8327\n",
      "Epoch 255/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3610 - accuracy: 0.8329\n",
      "Epoch 256/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3612 - accuracy: 0.8325\n",
      "Epoch 257/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3610 - accuracy: 0.8321\n",
      "Epoch 258/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3612 - accuracy: 0.8325\n",
      "Epoch 259/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3610 - accuracy: 0.8326\n",
      "Epoch 260/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3608 - accuracy: 0.8324\n",
      "Epoch 261/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3612 - accuracy: 0.8323\n",
      "Epoch 262/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3607 - accuracy: 0.8325\n",
      "Epoch 263/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3607 - accuracy: 0.8321\n",
      "Epoch 264/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3606 - accuracy: 0.8331\n",
      "Epoch 265/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3609 - accuracy: 0.8322\n",
      "Epoch 266/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3610 - accuracy: 0.8325\n",
      "Epoch 267/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3607 - accuracy: 0.8325\n",
      "Epoch 268/1000\n",
      "6646/6646 [==============================] - 10s 2ms/step - loss: 0.3608 - accuracy: 0.8326\n",
      "Epoch 269/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3605 - accuracy: 0.8328\n",
      "Epoch 270/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3605 - accuracy: 0.8325\n",
      "Epoch 271/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3605 - accuracy: 0.8324\n",
      "Epoch 272/1000\n",
      "6646/6646 [==============================] - 13s 2ms/step - loss: 0.3609 - accuracy: 0.8323\n",
      "Epoch 273/1000\n",
      "6646/6646 [==============================] - 11s 2ms/step - loss: 0.3607 - accuracy: 0.8325\n",
      "Epoch 274/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3607 - accuracy: 0.8324\n",
      "Epoch 275/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3605 - accuracy: 0.8326\n",
      "Epoch 276/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3603 - accuracy: 0.8329\n",
      "Epoch 277/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3605 - accuracy: 0.8332\n",
      "Epoch 278/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3605 - accuracy: 0.8327\n",
      "Epoch 279/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3606 - accuracy: 0.8327\n",
      "Epoch 280/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3603 - accuracy: 0.8329\n",
      "Epoch 281/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3606 - accuracy: 0.8329\n",
      "Epoch 282/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3605 - accuracy: 0.8328\n",
      "Epoch 283/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3602 - accuracy: 0.8331\n",
      "Epoch 284/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3605 - accuracy: 0.8334\n",
      "Epoch 285/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3604 - accuracy: 0.8325\n",
      "Epoch 286/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3607 - accuracy: 0.8324\n",
      "Epoch 287/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3604 - accuracy: 0.8329\n",
      "Epoch 288/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3604 - accuracy: 0.8327\n",
      "Epoch 289/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3602 - accuracy: 0.8328\n",
      "Epoch 290/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3603 - accuracy: 0.8325\n",
      "Epoch 291/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3601 - accuracy: 0.8334\n",
      "Epoch 292/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3601 - accuracy: 0.8329\n",
      "Epoch 293/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3603 - accuracy: 0.8325\n",
      "Epoch 294/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8326\n",
      "Epoch 295/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3603 - accuracy: 0.8326\n",
      "Epoch 296/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3606 - accuracy: 0.8323\n",
      "Epoch 297/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3602 - accuracy: 0.8329\n",
      "Epoch 298/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3603 - accuracy: 0.8326\n",
      "Epoch 299/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3602 - accuracy: 0.8332\n",
      "Epoch 300/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3604 - accuracy: 0.8328\n",
      "Epoch 301/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3602 - accuracy: 0.8329\n",
      "Epoch 302/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3603 - accuracy: 0.8330\n",
      "Epoch 303/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8333\n",
      "Epoch 304/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3603 - accuracy: 0.8328\n",
      "Epoch 305/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8328\n",
      "Epoch 306/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3601 - accuracy: 0.8329\n",
      "Epoch 307/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3602 - accuracy: 0.8327\n",
      "Epoch 308/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3597 - accuracy: 0.8333\n",
      "Epoch 309/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3600 - accuracy: 0.8326\n",
      "Epoch 310/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3598 - accuracy: 0.8338\n",
      "Epoch 311/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8340\n",
      "Epoch 312/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8329\n",
      "Epoch 313/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8332\n",
      "Epoch 314/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3597 - accuracy: 0.8329\n",
      "Epoch 315/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3600 - accuracy: 0.8331\n",
      "Epoch 316/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8330\n",
      "Epoch 317/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3600 - accuracy: 0.8330\n",
      "Epoch 318/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3598 - accuracy: 0.8335\n",
      "Epoch 319/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8333\n",
      "Epoch 320/1000\n",
      "6646/6646 [==============================] - 12s 2ms/step - loss: 0.3601 - accuracy: 0.8332\n",
      "Epoch 321/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3598 - accuracy: 0.8333\n",
      "Epoch 322/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3597 - accuracy: 0.8334\n",
      "Epoch 323/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8333\n",
      "Epoch 324/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3598 - accuracy: 0.8336\n",
      "Epoch 325/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8332\n",
      "Epoch 326/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8335\n",
      "Epoch 327/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8330\n",
      "Epoch 328/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3595 - accuracy: 0.8333\n",
      "Epoch 329/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8332\n",
      "Epoch 330/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3596 - accuracy: 0.8335\n",
      "Epoch 331/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3597 - accuracy: 0.8332\n",
      "Epoch 332/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3597 - accuracy: 0.8335\n",
      "Epoch 333/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3595 - accuracy: 0.8335\n",
      "Epoch 334/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3599 - accuracy: 0.8329\n",
      "Epoch 335/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3597 - accuracy: 0.8332\n",
      "Epoch 336/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8330\n",
      "Epoch 337/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8333\n",
      "Epoch 338/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3597 - accuracy: 0.8337\n",
      "Epoch 339/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3597 - accuracy: 0.8330\n",
      "Epoch 340/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3597 - accuracy: 0.8335\n",
      "Epoch 341/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3595 - accuracy: 0.8332\n",
      "Epoch 342/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3595 - accuracy: 0.8333\n",
      "Epoch 343/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8334\n",
      "Epoch 344/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3595 - accuracy: 0.8335\n",
      "Epoch 345/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8336\n",
      "Epoch 346/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8333\n",
      "Epoch 347/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3595 - accuracy: 0.8331\n",
      "Epoch 348/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8332\n",
      "Epoch 349/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8328\n",
      "Epoch 350/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3596 - accuracy: 0.8330\n",
      "Epoch 351/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8334\n",
      "Epoch 352/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3596 - accuracy: 0.8341\n",
      "Epoch 353/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3596 - accuracy: 0.8336\n",
      "Epoch 354/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3596 - accuracy: 0.8334\n",
      "Epoch 355/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3593 - accuracy: 0.8341\n",
      "Epoch 356/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3592 - accuracy: 0.8339\n",
      "Epoch 357/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3595 - accuracy: 0.8336\n",
      "Epoch 358/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3596 - accuracy: 0.8336\n",
      "Epoch 359/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8338\n",
      "Epoch 360/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3594 - accuracy: 0.8332\n",
      "Epoch 361/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3593 - accuracy: 0.8335\n",
      "Epoch 362/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3596 - accuracy: 0.8337\n",
      "Epoch 363/1000\n",
      "6646/6646 [==============================] - 9s 1ms/step - loss: 0.3591 - accuracy: 0.8332\n",
      "Epoch 364/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3592 - accuracy: 0.8336\n",
      "Epoch 365/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3592 - accuracy: 0.8332\n",
      "Epoch 366/1000\n",
      "6646/6646 [==============================] - 8s 1ms/step - loss: 0.3592 - accuracy: 0.8338\n",
      "Epoch 367/1000\n",
      "2630/6646 [==========>...................] - ETA: 4s - loss: 0.3573 - accuracy: 0.8346Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "# Neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation=\"relu\", input_dim=14))\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(5, activation=\"relu\"))\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=62)\n",
    "history = model.fit(X, y, epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1520,
     "status": "ok",
     "timestamp": 1605214363716,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "JBJBCtjNMXEK",
    "outputId": "75576274-8295-48b7-eeff-c62e2f7f63bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68215036, 0.31784967],\n",
       "       [0.35599956, 0.6440004 ],\n",
       "       [0.9638494 , 0.03615054],\n",
       "       ...,\n",
       "       [0.99817777, 0.00182225],\n",
       "       [0.8794975 , 0.12050244],\n",
       "       [0.3935796 , 0.6064204 ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preds = model.predict(X_test)\n",
    "preds = model.predict(X_test)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 353364,
     "status": "ok",
     "timestamp": 1605727085107,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "739F0FndQnQu",
    "outputId": "9c87cd4d-9b1f-48c8-eb69-9c72fa167443"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-c80a1ed0-c431-4c1f-aba9-4c7bb172f8f1\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-c80a1ed0-c431-4c1f-aba9-4c7bb172f8f1\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test.csv to test.csv\n"
     ]
    }
   ],
   "source": [
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "executionInfo": {
     "elapsed": 4190,
     "status": "ok",
     "timestamp": 1605727091839,
     "user": {
      "displayName": "Aitor Lucas",
      "photoUrl": "",
      "userId": "07298394126490224130"
     },
     "user_tz": -60
    },
    "id": "Y-Ns793lORv2",
    "outputId": "7c29037c-9e1e-435f-daeb-b62403692536"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_1c33374d-b42c-4923-b880-b4bd8a949b74\", \"predict.csv\", 2456033)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from google.colab import files\n",
    "\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test.drop([\"Id\"], axis=1, inplace=True)\n",
    "X_test = sc.fit_transform(test.iloc[:, :-1].values)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "pred_idx = np.arange(preds.shape[0])\n",
    "pred_1 = preds[:, 1]\n",
    "\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df[\"Id\"] = pred_idx\n",
    "pred_df[\"Predicted\"] = pred_1\n",
    "\n",
    "pred_df.to_csv(\"predict.csv\", index=False) \n",
    "files.download('predict.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMWCYv4RDxUC/XT91uwd/i5",
   "collapsed_sections": [],
   "name": "cern_NN_Aitor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
